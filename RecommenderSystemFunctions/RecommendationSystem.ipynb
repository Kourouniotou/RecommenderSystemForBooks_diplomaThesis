{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\image.py:172: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  dtype=np.int):\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tasos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tasos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tasos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tasos\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%run ../LibrariesAndFunctions/LibrariesFunctions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load LDA model, dictionary and corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "bookDataset = pd.read_csv(\"../Data/bookDataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "bookDataset[\"TokenLemNounsBigramTrigramRemStopWords\"] = bookDataset[\"TokenLemNounsBigramTrigramRemStopWords\"].apply(strToListOfStrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "ldaModelNouns =  gensim.models.LdaMulticore.load('../Lda Models/ldamodelNouns50_asymmetric_0.61.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "id2wordNouns = corpora.Dictionary.load('../Lda Models/ldamodelNouns50_asymmetric_0.61.model.id2word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "corpusNouns = [id2wordNouns.doc2bow(doc) for doc in bookDataset[\"TokenLemNounsBigramTrigramRemStopWords\"].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "from gensim import similarities\n",
    "simMatrix = similarities.MatrixSimilarity(corpusNouns, num_features=len(id2wordNouns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gensim.similarities.docsim.MatrixSimilarity"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(simMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "ratingsFinal = pd.read_csv('../Data/ratingsFinal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>ID</th>\n",
       "      <th>ISBN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agile web development with rails: a pragmatic guide</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49979</td>\n",
       "      <td>097669400X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agile web development with rails: a pragmatic guide</td>\n",
       "      <td>4.0</td>\n",
       "      <td>49992</td>\n",
       "      <td>097669400X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>agile web development with rails: a pragmatic guide</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50001</td>\n",
       "      <td>097669400X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agile web development with rails: a pragmatic guide</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50034</td>\n",
       "      <td>097669400X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agile web development with rails: a pragmatic guide</td>\n",
       "      <td>4.0</td>\n",
       "      <td>50050</td>\n",
       "      <td>097669400X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147768</th>\n",
       "      <td>fault lines: stories of divorce</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49882</td>\n",
       "      <td>0425188531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147769</th>\n",
       "      <td>is it too late to run away and join the circus?: finding the life you really want</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49891</td>\n",
       "      <td>0028620585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147770</th>\n",
       "      <td>mistress of falcon court</td>\n",
       "      <td>3.5</td>\n",
       "      <td>49900</td>\n",
       "      <td>0821726595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147771</th>\n",
       "      <td>inner hunger: a young woman's struggle through anorexia and bulimia</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49944</td>\n",
       "      <td>0393045900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147772</th>\n",
       "      <td>all elevations unknown: an adventure in the heart of borneo</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49976</td>\n",
       "      <td>0767907752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147773 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     Name  \\\n",
       "0                                     agile web development with rails: a pragmatic guide   \n",
       "1                                     agile web development with rails: a pragmatic guide   \n",
       "2                                     agile web development with rails: a pragmatic guide   \n",
       "3                                     agile web development with rails: a pragmatic guide   \n",
       "4                                     agile web development with rails: a pragmatic guide   \n",
       "...                                                                                   ...   \n",
       "147768                                                    fault lines: stories of divorce   \n",
       "147769  is it too late to run away and join the circus?: finding the life you really want   \n",
       "147770                                                           mistress of falcon court   \n",
       "147771                inner hunger: a young woman's struggle through anorexia and bulimia   \n",
       "147772                        all elevations unknown: an adventure in the heart of borneo   \n",
       "\n",
       "        Rating     ID        ISBN  \n",
       "0          5.0  49979  097669400X  \n",
       "1          4.0  49992  097669400X  \n",
       "2          5.0  50001  097669400X  \n",
       "3          4.0  50034  097669400X  \n",
       "4          4.0  50050  097669400X  \n",
       "...        ...    ...         ...  \n",
       "147768     3.0  49882  0425188531  \n",
       "147769     5.0  49891  0028620585  \n",
       "147770     3.5  49900  0821726595  \n",
       "147771     5.0  49944  0393045900  \n",
       "147772     3.0  49976  0767907752  \n",
       "\n",
       "[147773 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsFinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(147773, 4)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsFinal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=5, max_df=0.95)\n",
    "# fit_transform applies TF-IDF to clean texts - we save the array of vectors in X\n",
    "#partOfBooksForLdaFinal[\"TokenLemNounsBigramTrigramRemStopWords\"] = partOfBooksForLdaFinal[\"TokenLemNounsBigramTrigramRemStopWords\"].apply(strToListOfStrs)\n",
    "partOfBooksForLdaFinal[\"TokenLemNounsBigramTrigramRemStopWordsSent\"] = partOfBooksForLdaFinal[\"TokenLemNounsBigramTrigramRemStopWords\"].apply(listOfStingsToString)\n",
    "X = vectorizer.fit_transform(partOfBooksForLdaFinal[\"TokenLemNounsBigramTrigramRemStopWordsSent\"])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.feature_extraction.text import CountVectorizer\n",
    "meanEachTopic = []\n",
    "for eachTopic in partOfBooksForLdaFinal['Topic'].unique():\n",
    "    vectorizer = CountVectorizer()\n",
    "    tfidfDocs = vectorizer.fit_transform(partOfBooksForLdaFinal[partOfBooksForLdaFinal['Topic'] == eachTopic][\"TokenLemNounsBigramTrigramRemStopWordsSent\"])\n",
    "    meanEachTopic.append(np.triu(cosine_similarity(tfidfDocs, tfidfDocs), 1).mean()) \n",
    "mean(meanEachTopic)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We find the topic with highest probability(which save to the \"Probability\" column) for each document and we save it to \"Topic\" column. Αt the same time in \"topicDistribution\" column we store the total vector with the probabiltiy distribution for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "docNum, topicNum, prob = [], [], []\n",
    "topicDistributionInDocs = []\n",
    "for n in range(len(bookDataset)):\n",
    "    getDocumentTopics = ldaModelNouns.get_document_topics(corpusNouns[n])\n",
    "    distribution =[prob for (topic, prob) in getDocumentTopics]   \n",
    "    topicDistributionInDocs.append(distribution)\n",
    "    docNum.append(n)\n",
    "    sortedDocTopics = sortTuple(getDocumentTopics)\n",
    "    topicNum.append(sortedDocTopics[0][0])\n",
    "    prob.append(sortedDocTopics[0][1])\n",
    "bookDataset['Doc'] = docNum\n",
    "bookDataset['Topic'] = topicNum\n",
    "bookDataset['Probability'] = prob\n",
    "topicDistributionInDocs = pd.DataFrame(topicDistributionInDocs)\n",
    "topicDistributionInDocs[\"topicDistribution\"] =topicDistributionInDocs.values.tolist()\n",
    "bookDataset[\"topicDistribution\"] = topicDistributionInDocs[\"topicDistribution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(106432, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distOfDocs = np.array(bookDataset[\"topicDistribution\"].values.tolist())\n",
    "distOfDocs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If user enter a book that doesn't exist in our dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recommendation based on highest topic probability:\n",
    "### user input: book title\n",
    "### system: groupby the books by topic and sort them \n",
    "### output: books that belongs at the same topic with the topic of the book that the user entered and were in the same probability region in the sorted list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendByTitleHighestProb(userInput, df, ratings):\n",
    "    recommended = []\n",
    "    userInput = lowerCasing(userInput)\n",
    "    \n",
    "    if(userInput not in df.Name.values):\n",
    "        tfidf= TfidfVectorizer(token_pattern=u'\\S+')\n",
    "        titleTfidfMatrix = tfidf.fit_transform(df[\"NameForSearch\"].values)\n",
    "        tfidfInput = tfidf.transform([userInput])\n",
    "        cosSimTitle = cosine_similarity(titleTfidfMatrix, tfidfInput)\n",
    "        recommend = pd.Series(cosSimTitle.flatten()).sort_values(ascending = False)\n",
    "        recommend = recommend[0:20]\n",
    "        top10Index = recommend.index\n",
    "        for i in top10Index:\n",
    "            recommended.append(df.Name.iloc[i])\n",
    "    else:\n",
    "        recommended = recommendByTitleExist(userInput, df, ratings)\n",
    "    return recommended\n",
    "\n",
    "def recommendByTitleExist(userTitle, df, ratingsDf):\n",
    "    recommended = []\n",
    "    top10_list = []\n",
    "    description = []\n",
    "    userTitle = lowerCasing(userTitle)\n",
    "    topic_num = df[df['Name'] == userTitle].Topic.values\n",
    "    doc_num = df[df['Name'] == userTitle].Doc.values    \n",
    "\n",
    "    output_df = df[df['Topic']==topic_num[0]].sort_values('Probability', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    index = output_df[output_df['Doc']==doc_num[0]].index[0]\n",
    "    \n",
    "    top10_list += list(output_df.iloc[index-5:index].index)\n",
    "    top10_list += list(output_df.iloc[index+1:index+6].index)\n",
    "    \n",
    "    output_df['Name'] = output_df['Name'].str.title()\n",
    "\n",
    "    for each in top10_list:\n",
    "        recommended.append(output_df.iloc[each].Name.title())\n",
    "        recommended.append(output_df['Description print'].iloc[each])\n",
    "        recommended.append(\"                                             ⋆┈┈｡ﾟ❃ུ۪ ❀ུ۪ ❁ུ۪ ❃ུ۪ ❀ུ۪ ﾟ｡┈┈⋆                                             \")\n",
    "    users = recommendByUserPreferences(userTitle, ratingsDf, df)\n",
    "    if len(users) > 0:\n",
    "        recommended.append('\\n\\n\\nUser preferences:\\n\\n')\n",
    "        recommended.append(users)\n",
    "    return recommended, description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Recommendation Jensen Shannon:\n",
    "### user input: book name \n",
    "### if there is'not book with the user input name -> recommendByTitleNotExist\n",
    "### if there is a book with the user input name -> we find the topic distribution of the user's book and we and we apply the Jensen Shannon Divergence in order to suggest the books that have similar topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def jensenShannonDivergnece(query, matrix):\n",
    "    query = query.flatten()\n",
    "    p = query[None,:].T  + np.zeros([matrix.shape[1], matrix.shape[0]])# take transpose\n",
    "    q = matrix.T # transpose matrix\n",
    "    m = 0.5*(p + q)\n",
    "    \n",
    "    return np.sqrt(0.5*(entropy(p,m) + entropy(q,m)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "<>:9: DeprecationWarning: invalid escape sequence \\S\n",
      "<>:9: DeprecationWarning: invalid escape sequence \\S\n",
      "<ipython-input-53-1da86cbf1a5b>:9: DeprecationWarning: invalid escape sequence \\S\n",
      "  tfidf= TfidfVectorizer(token_pattern=u'\\S+')\n"
     ]
    }
   ],
   "source": [
    "def recommendByTopicDistr(userInput, df, ratings, isbn):\n",
    "    recommendedBooks = []\n",
    "    recommendedUsers = []\n",
    "    search = 1\n",
    "    counter = 0\n",
    "    if not isbn:\n",
    "        userInput = lowerCasing(userInput)\n",
    "        if(userInput not in df.Name.values):\n",
    "            tfidf= TfidfVectorizer(token_pattern=u'\\S+')\n",
    "            titleTfidfMatrix = tfidf.fit_transform(df[\"NameForSearch\"].values.astype('U'))\n",
    "            \n",
    "            for word in userInput.split():\n",
    "                if word in tfidf.get_feature_names():\n",
    "                    counter +=1\n",
    "                    break\n",
    "                    \n",
    "            if(counter==0):\n",
    "                search = 0\n",
    "                        \n",
    "            tfidfInput = tfidf.transform([userInput])\n",
    "            cosSimTitle = cosine_similarity(titleTfidfMatrix, tfidfInput)\n",
    "            \n",
    "            recommend = pd.Series(cosSimTitle.flatten()).sort_values(ascending = False)\n",
    "            \n",
    "            recommend = recommend[0:20]\n",
    "            recommend = recommend[recommend[:]!=0]\n",
    "            top10Index = recommend.index\n",
    "            for i in top10Index:\n",
    "                recommendedBooks.append(df.Name.iloc[i].title())\n",
    "                recommendedBooks.append(\"                                             ⋆┈┈｡ﾟ❃ུ۪ ❀ུ۪ ❁ུ۪ ❃ུ۪ ❀ུ۪ ﾟ｡┈┈⋆                                             \")\n",
    "  \n",
    "        else:\n",
    "            recommendedBooks, recommendedUsers = recommendByJensenShannonExist(userInput, df, ratings, isbn)\n",
    "    else:\n",
    "        if(userInput not in df.ISBN.values):\n",
    "            search = 1\n",
    "        else:\n",
    "            recommendedBooks, recommendedUsers = recommendByJensenShannonExist(userInput, df, ratings, isbn)   \n",
    "    return search, recommendedBooks, recommendedUsers\n",
    "    \n",
    "        \n",
    "def recommendByJensenShannonExist(userInput, df, ratingsDf, isbn):\n",
    "    recommendBooks = []\n",
    "    recommendUsers = []\n",
    "    searchDocSimilarity = []\n",
    "    \n",
    "    if isbn:\n",
    "         index = df[df[\"ISBN\"] == userInput].index.to_list()\n",
    "    else:\n",
    "        index = df[df[\"Name\"] == userInput.lower()].index.to_list()\n",
    "\n",
    "    searchDocSimilarity = jensenShannonDivergnece(distOfDocs[index],distOfDocs)\n",
    "     \n",
    "    sortSearchDocSimilarity = sorted(enumerate(searchDocSimilarity), key=lambda i: i[1])\n",
    "    \n",
    "    count = 0\n",
    "    for (pos, jensenShannon) in sortSearchDocSimilarity[0::]:\n",
    "        if jensenShannon >0.35 or count>16:\n",
    "            break\n",
    "        recommendBooks.append(df[\"Name\"].iloc[pos].title())\n",
    "        recommendBooks.append(df[\"ISBN\"].iloc[pos])\n",
    "        recommendBooks.append(df['Description print'].iloc[pos])\n",
    "        recommendBooks.append(\"                                             ⋆┈┈｡ﾟ❃ུ۪ ❀ུ۪ ❁ུ۪ ❃ུ۪ ❀ུ۪ ﾟ｡┈┈⋆                                             \")\n",
    "  \n",
    "        count += 1\n",
    "    \n",
    "    if not isbn:\n",
    "        users = recommendByTitleUserPreferences(userInput, ratingsDf, df)\n",
    "        if len(users) > 1:\n",
    "            recommendUsers = users\n",
    "        else:\n",
    "            recommendUsers.append('Τhere is no user who has read this book.')\n",
    "    else:\n",
    "        users = recommendByISBNUserPreferences(userInput, ratingsDf, df)\n",
    "        if len(users) > 1:\n",
    "            recommendUsers = users\n",
    "        else:\n",
    "            recommendUsers.append('Τhere is no user who has read this book.')\n",
    "    \n",
    "    return recommendBooks, recommendUsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recommendation based on higher topic probability:\n",
    "### user input: book ISBN\n",
    "### system: groupby the books by topic and sort them \n",
    "### output: books that belongs at the same topic with the topic of the book that the user entered and were in the same probability region in the sorted list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendByISBNHighestProb(userInput, df):\n",
    "    recommended = []\n",
    "    \n",
    "    if(userInput not in df.ISBN.values):\n",
    "        recommended = 0\n",
    "    else:\n",
    "        print(\"eimai edw\")\n",
    "        #recommended = recommendByISBNExist(userInput, df)\n",
    "        \n",
    "    return recommended\n",
    "\n",
    "def recommendByISBNExist(userISBN, df):\n",
    "    recommended = []\n",
    "    desc = []\n",
    "\n",
    "    topic_num = df[df['ISBN']==userISBN].Topic.values\n",
    "    doc_num = df[df['ISBN']==userISBN].Doc.values    \n",
    "    \n",
    "    output_df = df[df['Topic']==topic_num[0]].sort_values('Probability', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    index = output_df[output_df['Doc']==doc_num[0]].index[0]\n",
    "    \n",
    "    top10_list += list(output_df.iloc[index-5:index].index)\n",
    "    top10_list += list(output_df.iloc[index+1:index+6].index)\n",
    "    \n",
    "    output_df['Name'] = output_df['Name'].str.title()\n",
    "    \n",
    "    for each in top10_list:\n",
    "        recommended.append(output_df.iloc[each].Name.title())\n",
    "        recommended.append(output_df['Description print'].iloc[each])\n",
    "        recommended.append(\"                                             ⋆┈┈｡ﾟ❃ུ۪ ❀ུ۪ ❁ུ۪ ❃ུ۪ ❀ུ۪ ﾟ｡┈┈⋆                                             \")\n",
    "  \n",
    "    return recommended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Recommendation Jensen Shannon:\n",
    "### user input: book ISBN \n",
    "### if there is'not book with the user input isbn -> recommendByTitleNotExist\n",
    "### if there is a book with the user input isbn -> we find the topic distribution of the user's book and we and we apply the Jensen Shannon Divergence in order to suggest the books that have similar topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendByISBNTopicDistr(userInput, df):\n",
    "    recommended = []\n",
    "    \n",
    "    if(userInput not in df.ISBN.values):\n",
    "        recommended = 0\n",
    "    else:\n",
    "        recommended = recommendByISBNJensenShannonExist(userInput, df)   \n",
    "    return recommended\n",
    "\n",
    "def recommendByISBNJensenShannonExist(userISBN, df):\n",
    "    recommendBooks = []\n",
    "    searchDocSimilarity = []\n",
    "    topic = []\n",
    "    description = []\n",
    "    \n",
    "    index = df[df[\"ISBN\"] == userISBN].index.to_list()\n",
    "    \n",
    "    searchDocSimilarity = jensenShannonDivergnece(distOfDocs[index],distOfDocs)\n",
    "     \n",
    "    sortSearchDocSimilarity = sorted(enumerate(searchDocSimilarity), key=lambda i: i[1])\n",
    "    \n",
    "    count = 0\n",
    "    for (pos, jensenShannon) in sortSearchDocSimilarity[0::]:\n",
    "        if jensenShannon >=0.35 or count>16:\n",
    "            break\n",
    "        recommendBooks.append(df[\"Name\"].iloc[pos].title())\n",
    "        recommendBooks.append(df[\"ISBN\"].iloc[pos])\n",
    "        recommendBooks.append(df['Description print'].iloc[pos])\n",
    "        recommendBooks.append(\"                                             ⋆┈┈｡ﾟ❃ུ۪ ❀ུ۪ ❁ུ۪ ❃ུ۪ ❀ུ۪ ﾟ｡┈┈⋆                                             \")\n",
    "  \n",
    "        count += 1\n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, if user enter something like description or a stentence, we must tokenize, lemmatize, look about bigrams and trigrams, remove names and words with length < 2 and also remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "bigrams = pd.read_csv(\"../Data/bigrams60DescTitle.csv\")\n",
    "trigrams = pd.read_csv(\"../Data/trigrams60DescTitle.csv\")\n",
    "\n",
    "# Concatenate n-grams\n",
    "def replaceNgram(text, flag):\n",
    "    for gram in bigrams.Bigrams:\n",
    "        text = text.replace(gram, '_'.join(gram.split()))\n",
    "    if flag == 1:\n",
    "        for gram in trigrams.Trigrams:\n",
    "            text = text.replace(gram, '_'.join(gram.split()))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "englishNames = pd.read_csv('../Data/englishNames.txt', header=None)\n",
    "englishNames = pd.DataFrame(englishNames.values, columns = [\"Names\"])\n",
    "englishNames[\"Names\"] = englishNames[\"Names\"].apply(lowerCasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def prepareUserQuery(userQuery, bigrams, trigrams):\n",
    "    \n",
    "    userQuery = removeNewlines(userQuery)\n",
    "    userQuery = removeHtmlTags(userQuery)\n",
    "    userQuery = removeLinks(userQuery)\n",
    "    userQuery = lowerCasing(userQuery)\n",
    "    userQuery = reducingIncorrectCharacterRepeatation(userQuery)\n",
    "    userQuery = expandContractions(userQuery)\n",
    "    userQuery = removeSpecialCharacters(userQuery)\n",
    "    userQuery = removeNumbers(userQuery)\n",
    "    userQuery = removeWhitespace(userQuery)\n",
    "    \n",
    "    userQuery = sent2Words(userQuery)\n",
    "    \n",
    "    userQuery = lemmatizationAll(userQuery, 1)\n",
    "    \n",
    "    userQueryDf = pd.DataFrame()\n",
    "    userQuery = listOfStingsToString(userQuery)\n",
    "    userQuery = replaceNgram(userQuery, 0)\n",
    "    userQuery = [word for word in userQuery.split() if (word not in stopWords)\n",
    "                                                    and (len(word) > 2) \n",
    "                                                    and (word not in englishNames[\"Names\"].values)]\n",
    "    \n",
    "    userQuery = lemmatizationNouns(userQuery)\n",
    "    \n",
    "    return(userQuery) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RECOMMEND BY USER'S DESCRIPTION OF A BOOK THAT HE LIKES (JENSEN SHANNON)\n",
    "### return books that have similar topic distribution with the description that user enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def recommendByDescOfABookJensenShannon(userQuery, df):\n",
    "    queryDocSimilarity = []\n",
    "    recommend = []\n",
    "    topic = []\n",
    "    description = []\n",
    "    userQuery = prepareUserQuery(userQuery, bigrams, trigrams)\n",
    "    userQuery = id2wordNouns.doc2bow(userQuery)\n",
    "    \n",
    "    queryDistr = np.array([prob for (topic, prob) in ldaModelNouns.get_document_topics(userQuery)])\n",
    "    \n",
    "    queryDocSimilarity = jensenShannonDivergnece(queryDistr,distOfDocs)\n",
    "        \n",
    "    sortqueryDocSimilarity = sorted(enumerate(queryDocSimilarity), key=lambda i: i[1])\n",
    "    \n",
    "    count = 0\n",
    "    for (pos, jensenShannon) in sortqueryDocSimilarity:\n",
    "        if jensenShannon >=0.35 or count>16:\n",
    "            break\n",
    "        recommend.append(df[\"Name\"].iloc[pos].title())\n",
    "        recommend.append(df[\"ISBN\"].iloc[pos])\n",
    "        recommend.append(df['Description print'].iloc[pos])\n",
    "        recommend.append(\"                                             ⋆┈┈｡ﾟ❃ུ۪ ❀ུ۪ ❁ུ۪ ❃ུ۪ ❀ུ۪ ﾟ｡┈┈⋆                                             \")\n",
    "  \n",
    "        count += 1\n",
    "        \n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Recommend by a user query (a book that have recipes about mexican food)\n",
    "### we use the matrix that returns \"gensim.similarities import MatrixSimilarity\" which is something like a matrix  who has converted the documents into vector space and essentially the recommendation is made based on the words of the user's query that they correspond to the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def recommendByQuery(userQuery, similarityMatrix, df):\n",
    "    queryDocSimilarity = []\n",
    "    recommend = []\n",
    "    topic = []\n",
    "    \n",
    "    #epeksergasia query pros to paron den grafw tipota'\n",
    "    userQuery = prepareUserQuery(userQuery, bigrams, trigrams)\n",
    "    userQuery = id2wordNouns.doc2bow(userQuery)\n",
    "    resSim = similarityMatrix[userQuery]\n",
    "    \n",
    "    sortqueryDocSimilarity = sorted(enumerate(resSim), key=lambda i: i[1], reverse=True)\n",
    "\n",
    "    count = 0\n",
    "    for (pos, similarity) in sortqueryDocSimilarity:\n",
    "        if count>15 or similarity<0.1:\n",
    "            break\n",
    "        recommend.append(df[\"Name\"].iloc[pos].title())\n",
    "        recommend.append(df[\"ISBN\"].iloc[pos])\n",
    "        recommend.append(df['Description print'].iloc[pos])\n",
    "        recommend.append(\"                                             ⋆┈┈｡ﾟ❃ུ۪ ❀ུ۪ ❁ུ۪ ❃ུ۪ ❀ུ۪ ﾟ｡┈┈⋆                                             \")\n",
    "  \n",
    "        count += 1\n",
    "    \n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Recommend books by user preferences\n",
    "\n",
    "### user enter a book title and searching in list of user ratings for a rating at the user's entry book\n",
    "### If we find a lot we keep user idas and find all the other books that user read and we suggest  them with a series of more similar topic probabilistic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def recommendByTitleUserPreferences(userTitle, dfRatings, dfBooks):\n",
    "    users = []\n",
    "    recommend = []\n",
    "    appearance = dfRatings[dfRatings['Name'] == userTitle]\n",
    "    \n",
    "    if appearance.empty:\n",
    "        recommend = []\n",
    "    else:\n",
    "        users = appearance['ID'].values\n",
    "    \n",
    "        usersPref = dfRatings[dfRatings['ID'].isin(users)]\n",
    "\n",
    "        usersPrefWithoutEntry = usersPref[usersPref['Name']!=userTitle]\n",
    "\n",
    "        merge = pd.merge(usersPrefWithoutEntry, dfBooks[['ISBN', 'topicDistribution']]).drop_duplicates(['Name'])\n",
    "        \n",
    "        distrOfPref = np.array(merge[\"topicDistribution\"].values.tolist())\n",
    "\n",
    "        queryDistr = np.array(dfBooks[dfBooks['Name'] == userTitle][\"topicDistribution\"].values.tolist())\n",
    "        \n",
    "        queryDocSimilarity = jensenShannonDivergnece(queryDistr,distrOfPref)\n",
    "\n",
    "        sortqueryDocSimilarity = sorted(enumerate(queryDocSimilarity), key=lambda i: i[1])\n",
    "        \n",
    "        count = 0\n",
    "        recommend.append('Users suggest: \\n\\n')\n",
    "        for (pos, jensenShannon) in sortqueryDocSimilarity:\n",
    "            if jensenShannon <= 0.35 and count <= 15:\n",
    "                recommend.append(merge[\"Name\"].iloc[pos].title())\n",
    "                count += 1\n",
    "\n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommend books by user preferences\n",
    "\n",
    "### user enter a isbn and searching in list of user ratings for a rating at the user's entry book\n",
    "### If we find a lot we keep user idas and find all the other books that user read and we suggest  them with a series of more similar topic probabilistic distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasos\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "def recommendByISBNUserPreferences(userISBN, dfRatings, dfBooks):\n",
    "    users = []\n",
    "    recommend = []\n",
    "    appearance = dfRatings[dfRatings['ISBN'] == userISBN]\n",
    "\n",
    "    if appearance.empty:\n",
    "        recommend = []\n",
    "    else:\n",
    "        users = appearance['ID'].values\n",
    "    \n",
    "        usersPref = dfRatings[dfRatings['ID'].isin(users)]\n",
    "\n",
    "        usersPrefWithoutEntry = usersPref[usersPref['ISBN']!=userISBN]\n",
    "\n",
    "        merge = pd.merge(usersPrefWithoutEntry, dfBooks[['ISBN', 'topicDistribution']]).drop_duplicates(['Name'])\n",
    "\n",
    "        distrOfPref = np.array(merge[\"topicDistribution\"].values.tolist())\n",
    "\n",
    "        queryDistr = np.array(dfBooks[dfBooks['ISBN'] == userISBN][\"topicDistribution\"].values.tolist())\n",
    "        queryDocSimilarity = jensenShannonDivergnece(queryDistr,distrOfPref)\n",
    "\n",
    "        sortqueryDocSimilarity = sorted(enumerate(queryDocSimilarity), key=lambda i: i[1])\n",
    "\n",
    "        count = 0\n",
    "        recommend.append('\\nUsers suggest: \\n\\n')\n",
    "        for (pos, jensenShannon) in sortqueryDocSimilarity:\n",
    "            if jensenShannon <= 0.35 and count <= 15:\n",
    "                recommend.append(merge[\"Name\"].iloc[pos].title())\n",
    "                count += 1\n",
    "    \n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
